behaviors:
  FoxAgent:
    trainer_type: ppo

    hyperparameters:
      batch_size: 4096
      buffer_size: 32768
      learning_rate: 1.0e-4        # lower for stable finetune
      beta: 5.0e-4                 # lower entropy => less exploration
      epsilon: 0.2
      lambd: 0.95
      num_epoch: 4
      learning_rate_schedule: linear

    network_settings:
      normalize: true
      hidden_units: 512
      num_layers: 4
      vis_encode_type: resnet
      memory:
        sequence_length: 256
        memory_size: 128

    reward_signals:
      extrinsic:
        gamma: 0.995
        strength: 1.0
      # curiosity removed for exploitation focus

    behavioral_cloning:
      demo_path: 'Y:/Drive/My_Drive/folder/UU/Ai_for_games_proj/Python/Demos_high_g/'
      strength: 0.20               # lowered demo power
      steps: 1000000                # short warm-start, then pure PPO
      samples_per_update: 0        # default, keep if omitted

    max_steps: 5.0e7
    time_horizon: 256
    summary_freq: 5000
    keep_checkpoints: 15

    # Initialize weights from your latest checkpoint
    init_path: 'Y:/Drive/My_Drive/folder/UU/Ai_for_games_proj/Python/FoxAgent-5000097.pt'

torch_settings:
  device: cuda
